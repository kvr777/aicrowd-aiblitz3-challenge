{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"GPT2_fine-tune on fake news detection_max_seq110.ipynb","provenance":[{"file_id":"1IQbuBBHZ4tzRzXJpMWjVn-eH75lU0o5Q","timestamp":1598642650173},{"file_id":"11hsn7YKAoVAWXdT_PKOBx2cOpJp-WO96","timestamp":1598642053928},{"file_id":"1Bjnn2aL3MEPaxuFwgolcpo2tNBY0m3oa","timestamp":1598527577216},{"file_id":"1P4Hq0btDUDOTGkCHGzZbAx1lb0bTzMMa","timestamp":1598476095743},{"file_id":"1dEZF3LMCCQUAzf98rnrvT1bWnK6Jgh6U","timestamp":1591951041166}],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"d0ecdc25452544b296cb5062723a030d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_ad88bb350eec448489c554067d81168f","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_aeaaa422f6c3442fbd40fc071bbec564","IPY_MODEL_8a6b8d5dd3764da8900e606521bf90f6"]}},"ad88bb350eec448489c554067d81168f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"aeaaa422f6c3442fbd40fc071bbec564":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_9fd2d6872d3d4fb98f8141e4d3220fe5","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":1042301,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1042301,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_924ed7f5b932474388068511259e381d"}},"8a6b8d5dd3764da8900e606521bf90f6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_a7c8d30eb7714a13baf7d9eb098ae3c1","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1.04M/1.04M [00:02&lt;00:00, 389kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3d79ee0e48014498ba396ba162bdaa18"}},"9fd2d6872d3d4fb98f8141e4d3220fe5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"924ed7f5b932474388068511259e381d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a7c8d30eb7714a13baf7d9eb098ae3c1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"3d79ee0e48014498ba396ba162bdaa18":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f335cd5cb59c4ab897131933beae8df0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_864e4a290a34474882d714e66940a22f","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_47d5b0275a4d4ecc8edeff2b426cedd7","IPY_MODEL_169c0b84954d4d75a36ea3aa29bbc9ad"]}},"864e4a290a34474882d714e66940a22f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"47d5b0275a4d4ecc8edeff2b426cedd7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_13330e9d481b43cab5709e4841f5c9a4","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":456318,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":456318,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_8e941aaf88dc4ac18c6d4de7478c1e29"}},"169c0b84954d4d75a36ea3aa29bbc9ad":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_61b419501e1743dea14e1ae457dcfc0f","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 456k/456k [00:00&lt;00:00, 461kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ff5b7801c78b46f9ba3301e7c358ed8e"}},"13330e9d481b43cab5709e4841f5c9a4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"8e941aaf88dc4ac18c6d4de7478c1e29":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"61b419501e1743dea14e1ae457dcfc0f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"ff5b7801c78b46f9ba3301e7c358ed8e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"162456781407482c98f51a95a516b43d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_767fd00910bd40e0b5824492b37450d5","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_5d15fb4ebce84d45b20ae347cd9a9ff3","IPY_MODEL_c31b17cad3bd4a9abfc920140a538cd9"]}},"767fd00910bd40e0b5824492b37450d5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5d15fb4ebce84d45b20ae347cd9a9ff3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_e264fdae8fde4440ad16eeabe4c71c21","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":762,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":762,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_eb9f86329089493a8c356852e80ab155"}},"c31b17cad3bd4a9abfc920140a538cd9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_842a2b19cd3f4572a4fc5aa29d018bbf","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 762/762 [00:04&lt;00:00, 157B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d62d5834f5144a10b30ed116a9429687"}},"e264fdae8fde4440ad16eeabe4c71c21":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"eb9f86329089493a8c356852e80ab155":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"842a2b19cd3f4572a4fc5aa29d018bbf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"d62d5834f5144a10b30ed116a9429687":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2674121b3604426cbcdfb20dc10386f3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_7341fac71f6644ff9bb5ab1ccfa5dca9","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_d97454a1701a4b5f9b06680840ef9bf0","IPY_MODEL_11ecd549a12c4898ba725adab7a485fb"]}},"7341fac71f6644ff9bb5ab1ccfa5dca9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d97454a1701a4b5f9b06680840ef9bf0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_3f3e5a6bc0d54828b3c6aa663919e9f8","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":352833716,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":352833716,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_959478cfa5864be6ab0b0bb366defce8"}},"11ecd549a12c4898ba725adab7a485fb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_060ea4949fed42768a3fce08fc4c8d46","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 353M/353M [00:04&lt;00:00, 75.4MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_29513c34feec4529b8828addd3c9e753"}},"3f3e5a6bc0d54828b3c6aa663919e9f8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"959478cfa5864be6ab0b0bb366defce8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"060ea4949fed42768a3fce08fc4c8d46":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"29513c34feec4529b8828addd3c9e753":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8d46302640d948548435b669f05ac342":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_36d760197854495b8427bec29bd60319","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_b232b45f6a5841fea240858f2bea1ced","IPY_MODEL_36f4c87de1ca4d338677e7d9c2a80587"]}},"36d760197854495b8427bec29bd60319":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b232b45f6a5841fea240858f2bea1ced":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_2c33f8161a21417cbc86f212e0565370","_dom_classes":[],"description":"training_routine:  70%","_model_name":"FloatProgressModel","bar_style":"","max":10,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":7,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1c473249eb3e43a185538a9196974a85"}},"36f4c87de1ca4d338677e7d9c2a80587":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_108ae0e414e5477a872f83643216005d","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 7/10 [12:31:02&lt;5:44:05, 6881.90s/it, best_f1=0.996, current=0.996]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_94c0e1dfff7d41848e415e8eafb6d933"}},"2c33f8161a21417cbc86f212e0565370":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"1c473249eb3e43a185538a9196974a85":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"108ae0e414e5477a872f83643216005d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"94c0e1dfff7d41848e415e8eafb6d933":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7ffdaf4c6f2747c3a1925bad5b93ef15":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_081cf510f0c4469aaf8af68fd8dff6be","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_ac924148914f4be1a20aa5c50455839d","IPY_MODEL_1247334d9c954a0e933144629aac3aec"]}},"081cf510f0c4469aaf8af68fd8dff6be":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ac924148914f4be1a20aa5c50455839d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_61771ea31cef4d369417925b9934d37b","_dom_classes":[],"description":"split=train :  21%","_model_name":"FloatProgressModel","bar_style":"","max":11874,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":2479,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c78793f21e9f40dda839dcb1f301f104"}},"1247334d9c954a0e933144629aac3aec":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_8245ffd58707474594ef6b5f95bf6228","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 2479/11874 [25:33&lt;1:36:51,  1.62it/s, acc=0.999, epoch=7, f1=0.999, loss=0.00292]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_abd596bc5162405b81c97d07d498b308"}},"61771ea31cef4d369417925b9934d37b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"c78793f21e9f40dda839dcb1f301f104":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8245ffd58707474594ef6b5f95bf6228":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"abd596bc5162405b81c97d07d498b308":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"389e8a2a6604476ab40e04742926a87b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_ad042a20ef834759ad5c56539d5bfab3","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_8adf686c94fb491ab57c3d3b04f87287","IPY_MODEL_f4bbbd2b56dd4b15b8d71d7b5d451d9b"]}},"ad042a20ef834759ad5c56539d5bfab3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8adf686c94fb491ab57c3d3b04f87287":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_326062b079ce4e88ac79fb5c604fcc45","_dom_classes":[],"description":"split=eval: ","_model_name":"FloatProgressModel","bar_style":"","max":842,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":842,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_da4940e64565470ea1b08ddf88189d2c"}},"f4bbbd2b56dd4b15b8d71d7b5d451d9b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_44f92540cfd544a2be3661685e373f7a","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 843/? [02:54&lt;00:00,  4.94it/s, acc=0.997, epoch=6, f1=0.996, loss=0.0203]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_eeaef2ed0b6f4d1aa67401cebf7a0720"}},"326062b079ce4e88ac79fb5c604fcc45":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"da4940e64565470ea1b08ddf88189d2c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"44f92540cfd544a2be3661685e373f7a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"eeaef2ed0b6f4d1aa67401cebf7a0720":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"81805c7f41084f719672ea4990c83984":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_c6b4c5e473d146288b056438479290b7","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_e24ae2b08d6041a18d7d8608c089f32d","IPY_MODEL_92cec11d752c43a6aebede9d6a480a1f"]}},"c6b4c5e473d146288b056438479290b7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e24ae2b08d6041a18d7d8608c089f32d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_d75c558ed0ff4cc7a88f8eb87574984a","_dom_classes":[],"description":"split=train : ","_model_name":"FloatProgressModel","bar_style":"","max":5799,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":5799,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f039b40c690c4b79aa655b47eecc9e18"}},"92cec11d752c43a6aebede9d6a480a1f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_8c5ebad578354148888f80e46de77db5","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 5800/? [19:32&lt;00:00,  4.96it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_44b2dca72ce64efe925b593e95163ba9"}},"d75c558ed0ff4cc7a88f8eb87574984a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"f039b40c690c4b79aa655b47eecc9e18":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8c5ebad578354148888f80e46de77db5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"44b2dca72ce64efe925b593e95163ba9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"78918d72c2164a06aa7bf7dd57a95e83":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_61589b68224f47c989ba5ae43e9f0a85","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_d42bfb5da79e439da689951eda3d1337","IPY_MODEL_85998eca31ca4fd1b88364d525bb3399"]}},"61589b68224f47c989ba5ae43e9f0a85":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d42bfb5da79e439da689951eda3d1337":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_b33896004f7c46a6bb72f6be967ff917","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":6,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":6,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ea557695256a4fd7a4e399e8c650bd87"}},"85998eca31ca4fd1b88364d525bb3399":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_d8721c97f7e84f5baa8d524aa65b1e53","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 6/6 [2:32:09&lt;00:00, 1521.63s/it]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_35ac9638991a49688002c22a694802f2"}},"b33896004f7c46a6bb72f6be967ff917":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"ea557695256a4fd7a4e399e8c650bd87":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d8721c97f7e84f5baa8d524aa65b1e53":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"35ac9638991a49688002c22a694802f2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"source":["## This model is based on GPT2 model fine-tuning"],"cell_type":"markdown","metadata":{}},{"cell_type":"code","metadata":{"id":"ZZBrsWSzq0_B","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":127},"executionInfo":{"status":"ok","timestamp":1598965611216,"user_tz":-180,"elapsed":26617,"user":{"displayName":"Kirill Romanov","photoUrl":"","userId":"02666825069423801309"}},"outputId":"dec415ff-be03-4217-fe9a-acfeef86afe4"},"source":["from google.colab import drive\n","drive.mount(\"/content/drive\")"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"rv_UDdeamlNp","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1598965636440,"user_tz":-180,"elapsed":21361,"user":{"displayName":"Kirill Romanov","photoUrl":"","userId":"02666825069423801309"}},"outputId":"8a87e9b4-1906-470d-a24e-72e5a1323949"},"source":["!rm -rf data\n","!mkdir data\n","!wget https://datasets.aicrowd.com/default/aicrowd-practice-challenges/public/fnews/v0.1/train.zip\n","!wget https://datasets.aicrowd.com/default/aicrowd-practice-challenges/public/fnews/v0.1/val.zip\n","!wget https://datasets.aicrowd.com/default/aicrowd-practice-challenges/public/fnews/v0.1/test.zip\n","!unzip train.zip\n","!unzip val.zip\n","!unzip test.zip\n","!mv train.csv data/train.csv\n","!mv val.csv data/val.csv\n","!mv test.csv data/test.csv\n","!mkdir model"],"execution_count":2,"outputs":[{"output_type":"stream","text":["--2020-09-01 13:06:56--  https://datasets.aicrowd.com/default/aicrowd-practice-challenges/public/fnews/v0.1/train.zip\n","Resolving datasets.aicrowd.com (datasets.aicrowd.com)... 35.189.208.115\n","Connecting to datasets.aicrowd.com (datasets.aicrowd.com)|35.189.208.115|:443... connected.\n","HTTP request sent, awaiting response... 302 FOUND\n","Location: https://s3.us-west-002.backblazeb2.com/aicrowd-practice-challenges/public/fnews/v0.1/train.zip?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=002ae2491b744be0000000002%2F20200901%2Fus-west-002%2Fs3%2Faws4_request&X-Amz-Date=20200901T130657Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=43190380c338f631f6bf4839cd55ba7339fa4703b272992d42af1a124216894f [following]\n","--2020-09-01 13:06:57--  https://s3.us-west-002.backblazeb2.com/aicrowd-practice-challenges/public/fnews/v0.1/train.zip?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=002ae2491b744be0000000002%2F20200901%2Fus-west-002%2Fs3%2Faws4_request&X-Amz-Date=20200901T130657Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=43190380c338f631f6bf4839cd55ba7339fa4703b272992d42af1a124216894f\n","Resolving s3.us-west-002.backblazeb2.com (s3.us-west-002.backblazeb2.com)... 206.190.215.254\n","Connecting to s3.us-west-002.backblazeb2.com (s3.us-west-002.backblazeb2.com)|206.190.215.254|:443... connected.\n","HTTP request sent, awaiting response... 200 \n","Length: 33386653 (32M) [application/zip]\n","Saving to: ‘train.zip’\n","\n","train.zip           100%[===================>]  31.84M  8.07MB/s    in 3.9s    \n","\n","2020-09-01 13:07:03 (8.07 MB/s) - ‘train.zip’ saved [33386653/33386653]\n","\n","--2020-09-01 13:07:03--  https://datasets.aicrowd.com/default/aicrowd-practice-challenges/public/fnews/v0.1/val.zip\n","Resolving datasets.aicrowd.com (datasets.aicrowd.com)... 35.189.208.115\n","Connecting to datasets.aicrowd.com (datasets.aicrowd.com)|35.189.208.115|:443... connected.\n","HTTP request sent, awaiting response... 302 FOUND\n","Location: https://s3.us-west-002.backblazeb2.com/aicrowd-practice-challenges/public/fnews/v0.1/val.zip?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=002ae2491b744be0000000002%2F20200901%2Fus-west-002%2Fs3%2Faws4_request&X-Amz-Date=20200901T130705Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=d2ddf1eff6f4bff9c47db07ce1740a16fa5480a74447f860ba7e2ab177b6872b [following]\n","--2020-09-01 13:07:05--  https://s3.us-west-002.backblazeb2.com/aicrowd-practice-challenges/public/fnews/v0.1/val.zip?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=002ae2491b744be0000000002%2F20200901%2Fus-west-002%2Fs3%2Faws4_request&X-Amz-Date=20200901T130705Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=d2ddf1eff6f4bff9c47db07ce1740a16fa5480a74447f860ba7e2ab177b6872b\n","Resolving s3.us-west-002.backblazeb2.com (s3.us-west-002.backblazeb2.com)... 206.190.215.254\n","Connecting to s3.us-west-002.backblazeb2.com (s3.us-west-002.backblazeb2.com)|206.190.215.254|:443... connected.\n","HTTP request sent, awaiting response... 200 \n","Length: 5564345 (5.3M) [application/zip]\n","Saving to: ‘val.zip’\n","\n","val.zip             100%[===================>]   5.31M  4.62MB/s    in 1.1s    \n","\n","2020-09-01 13:07:07 (4.62 MB/s) - ‘val.zip’ saved [5564345/5564345]\n","\n","--2020-09-01 13:07:07--  https://datasets.aicrowd.com/default/aicrowd-practice-challenges/public/fnews/v0.1/test.zip\n","Resolving datasets.aicrowd.com (datasets.aicrowd.com)... 35.189.208.115\n","Connecting to datasets.aicrowd.com (datasets.aicrowd.com)|35.189.208.115|:443... connected.\n","HTTP request sent, awaiting response... 302 FOUND\n","Location: https://s3.us-west-002.backblazeb2.com/aicrowd-practice-challenges/public/fnews/v0.1/test.zip?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=002ae2491b744be0000000002%2F20200901%2Fus-west-002%2Fs3%2Faws4_request&X-Amz-Date=20200901T130709Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=0b987a524d3c6ee98f6d7eec6a5f3b8ada8731320212fb6c8585d75ec12a75cb [following]\n","--2020-09-01 13:07:09--  https://s3.us-west-002.backblazeb2.com/aicrowd-practice-challenges/public/fnews/v0.1/test.zip?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=002ae2491b744be0000000002%2F20200901%2Fus-west-002%2Fs3%2Faws4_request&X-Amz-Date=20200901T130709Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=0b987a524d3c6ee98f6d7eec6a5f3b8ada8731320212fb6c8585d75ec12a75cb\n","Resolving s3.us-west-002.backblazeb2.com (s3.us-west-002.backblazeb2.com)... 206.190.215.254\n","Connecting to s3.us-west-002.backblazeb2.com (s3.us-west-002.backblazeb2.com)|206.190.215.254|:443... connected.\n","HTTP request sent, awaiting response... 200 \n","Length: 16636215 (16M) [application/zip]\n","Saving to: ‘test.zip’\n","\n","test.zip            100%[===================>]  15.87M  9.29MB/s    in 1.7s    \n","\n","2020-09-01 13:07:14 (9.29 MB/s) - ‘test.zip’ saved [16636215/16636215]\n","\n","Archive:  train.zip\n","  inflating: train.csv               \n","Archive:  val.zip\n","  inflating: val.csv                 \n","Archive:  test.zip\n","  inflating: test.csv                \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bY4NR2cVZNFA","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":685},"executionInfo":{"status":"ok","timestamp":1598965645801,"user_tz":-180,"elapsed":27565,"user":{"displayName":"Kirill Romanov","photoUrl":"","userId":"02666825069423801309"}},"outputId":"713a5e3e-f0d8-4a31-c8fb-2ddb2f3dfcec"},"source":["!pip install transformers\n","!python -c 'import nltk; nltk.download(\"punkt\")'"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/05/c8c55b600308dc04e95100dc8ad8a244dd800fe75dfafcf1d6348c6f6209/transformers-3.1.0-py3-none-any.whl (884kB)\n","\u001b[K     |████████████████████████████████| 890kB 2.7MB/s \n","\u001b[?25hCollecting tokenizers==0.8.1.rc2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/83/8b9fccb9e48eeb575ee19179e2bdde0ee9a1904f97de5f02d19016b8804f/tokenizers-0.8.1rc2-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n","\u001b[K     |████████████████████████████████| 3.0MB 15.8MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n","Collecting sentencepiece!=0.1.92\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n","\u001b[K     |████████████████████████████████| 1.1MB 30.5MB/s \n","\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n","\u001b[K     |████████████████████████████████| 890kB 21.1MB/s \n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=c1a9825e778516978c1c62875be325dfcddf6f2bd896c174c81459dfa63672f9\n","  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n","Successfully built sacremoses\n","Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers\n","Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.1rc2 transformers-3.1.0\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"dl7rqQ4uZPiv","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598972965813,"user_tz":-180,"elapsed":1521,"user":{"displayName":"Kirill Romanov","photoUrl":"","userId":"02666825069423801309"}}},"source":["# Libraries\n","\n","import matplotlib.pyplot as plt\n","import pprint\n","import pandas as pd\n","import numpy as np\n","import torch\n","import os\n","import nltk\n","from torch.optim import Optimizer\n","import itertools as it\n","import math\n","from typing import Callable\n","import gc\n","from argparse import Namespace\n","from collections import defaultdict, Counter\n","import random\n","from tqdm import notebook\n","\n","from sklearn.metrics import classification_report\n","from sklearn.metrics import confusion_matrix\n","from sklearn.metrics import accuracy_score\n","from sklearn.metrics import f1_score\n","\n","\n","import torch.nn as nn\n","from torch.optim.optimizer import Optimizer, required\n","from typing import Callable\n","from torch.utils.data import Dataset, DataLoader\n","import torch.optim as optim\n","\n","\n","from transformers import GPT2Tokenizer, GPT2Model\n","\n","from sklearn.model_selection import train_test_split\n","import seaborn as sns"],"execution_count":36,"outputs":[]},{"cell_type":"code","metadata":{"id":"vgWQpD-Xh-Zg","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598965651315,"user_tz":-180,"elapsed":27531,"user":{"displayName":"Kirill Romanov","photoUrl":"","userId":"02666825069423801309"}}},"source":["def make_train_state():\n","    d = {\n","        \"train_preds\": [],\n","        \"train_indexes\": [],\n","        \"train_targets\": [],\n","        \"train_accuracies\": [],\n","        \"train_f1s\": [],\n","        \"train_losses\": [],\n","        \"val_preds\": [],\n","        \"val_indexes\": [],\n","        \"val_targets\": [],\n","        \"val_accuracies\": [],\n","        \"val_f1s\": [],\n","        \"val_losses\": [],\n","        \"test_preds\": [],\n","        \"test_indexes\": [],\n","        \"test_targets\": [],\n","        \"test_accuracies\": [],\n","        \"test_f1s\": [],\n","        \"test_losses\": [],\n","        \"batch_preds\": [],\n","        \"batch_targets\": [],\n","        \"batch_indexes\": [],\n","        \"epoch_index\": 0,\n","        # \"save_path\": ''\n","    }\n","    return dict(d)\n","\n","\n","def set_seed_everywhere(seed=42):\n","    np.random.seed(seed)\n","    random.seed(seed)\n","    torch.manual_seed(seed)\n","    if torch.cuda.is_available():\n","        torch.cuda.manual_seed_all(seed)"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"GP73bp0dhrVH","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598965651316,"user_tz":-180,"elapsed":27027,"user":{"displayName":"Kirill Romanov","photoUrl":"","userId":"02666825069423801309"}}},"source":["class EarlyStopping:\n","    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n","    def __init__(self, patience=7, verbose=False, delta=0):\n","        \"\"\"\n","        Args:\n","            patience (int): How long to wait after last time validation loss improved.\n","                            Default: 7\n","            verbose (bool): If True, prints a message for each validation loss improvement. \n","                            Default: False\n","            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n","                            Default: 0\n","        \"\"\"\n","        self.patience = patience\n","        self.verbose = verbose\n","        self.counter = 0\n","        self.best_score = None\n","        self.early_stop = False\n","        self.val_loss_min = np.Inf\n","        self.delta = delta\n","\n","    def __call__(self, val_loss, model):\n","\n","        score = val_loss\n","\n","        if self.best_score is None:\n","            self.best_score = score\n","            self.save_checkpoint(val_loss, model)\n","        elif score < self.best_score + self.delta:\n","            self.counter += 1\n","            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n","            if self.counter >= self.patience:\n","                self.early_stop = True\n","        else:\n","            self.best_score = score\n","            self.save_checkpoint(val_loss, model)\n","            self.counter = 0\n","\n","    def save_checkpoint(self, val_loss, model):\n","        '''Saves model when validation loss decrease.'''\n","        if self.verbose:\n","            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n","        torch.save(model.state_dict(), 'checkpoint.pt')\n","        self.val_loss_min = val_loss\n","\n","def compute_accuracy(y_pred, y_target):\n","    y_pred = y_pred.cpu()\n","    y_target = y_target.cpu()\n","    return torch.eq(torch.argmax(y_pred,dim=1),y_target).sum().item() / len(y_pred)\n","\n","def compute_macro_f1(y_pred, y_target, average = 'macro'):\n","    y_pred = (torch.argmax(y_pred,dim=1)).cpu().long().numpy()\n","    y_target = y_target.cpu().numpy()\n","\n","    return f1_score(y_true = y_target, y_pred=y_pred , average=average)\n","\n","\n","def analyse_preds(y_pred, y_target, threshold=0.5):\n","    y_pred = (torch.argmax(y_pred,dim=1) > threshold).cpu().long().numpy()\n","    # y_pred = (torch.argmax(y_pred > threshold,dim=1)).cpu().long().numpy()\n","    y_target = y_target.cpu().numpy()\n","\n","    conmat = confusion_matrix(y_pred=y_pred, y_true=y_target)\n","    confusion = pd.DataFrame(\n","        conmat, index=[\"NOT\", \"HS\"], columns=[\"predicted_NOT\", \"predicted_HS\"]\n","    )\n","    print(\"acc = \", accuracy_score(y_pred=y_pred, y_true=y_target))\n","    print(classification_report(y_pred=y_pred, y_true=y_target, digits=4))\n","    print(confusion)\n","\n","def analyse_preds2(y_pred, y_target, threshold=0.5):\n","    # y_pred = (torch.argmax(y_pred,dim=1) > threshold).cpu().long().numpy()\n","    y_pred = torch.argmax(nn.Sigmoid()(y_pred) > threshold,dim=1).cpu().long().numpy()\n","    y_target = y_target.cpu().numpy()\n","\n","    conmat = confusion_matrix(y_pred=y_pred, y_true=y_target)\n","    confusion = pd.DataFrame(\n","        conmat, index=[\"NOT\", \"HS\"], columns=[\"predicted_NOT\", \"predicted_HS\"]\n","    )\n","    print(\"acc = \", accuracy_score(y_pred=y_pred, y_true=y_target))\n","    print(classification_report(y_pred=y_pred, y_true=y_target, digits=4))\n","    print(confusion)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"25uxrnAlWOcR","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598965651317,"user_tz":-180,"elapsed":25760,"user":{"displayName":"Kirill Romanov","photoUrl":"","userId":"02666825069423801309"}}},"source":["class Lookahead(Optimizer):\n","    '''\n","    PyTorch implementation of the lookahead wrapper.\n","    Lookahead Optimizer: https://arxiv.org/abs/1907.08610\n","    '''\n","    def __init__(self, optimizer,alpha=0.5, k=6,pullback_momentum=\"none\"):\n","        '''\n","        :param optimizer:inner optimizer\n","        :param k (int): number of lookahead steps\n","        :param alpha(float): linear interpolation factor. 1.0 recovers the inner optimizer.\n","        :param pullback_momentum (str): change to inner optimizer momentum on interpolation update\n","        '''\n","        if not 0.0 <= alpha <= 1.0:\n","            raise ValueError(f'Invalid slow update rate: {alpha}')\n","        if not 1 <= k:\n","            raise ValueError(f'Invalid lookahead steps: {k}')\n","        self.optimizer = optimizer\n","        self.param_groups = self.optimizer.param_groups\n","        self.alpha = alpha\n","        self.k = k\n","        self.step_counter = 0\n","        assert pullback_momentum in [\"reset\", \"pullback\", \"none\"]\n","        self.pullback_momentum = pullback_momentum\n","        self.state = defaultdict(dict)\n","\n","        # Cache the current optimizer parameters\n","        for group in self.optimizer.param_groups:\n","            for p in group['params']:\n","                param_state = self.state[p]\n","                param_state['cached_params'] = torch.zeros_like(p.data)\n","                param_state['cached_params'].copy_(p.data)\n","\n","    def __getstate__(self):\n","        return {\n","            'state': self.state,\n","            'optimizer': self.optimizer,\n","            'alpha': self.alpha,\n","            'step_counter': self.step_counter,\n","            'k':self.k,\n","            'pullback_momentum': self.pullback_momentum\n","        }\n","\n","    def zero_grad(self):\n","        self.optimizer.zero_grad()\n","\n","    def state_dict(self):\n","        return self.optimizer.state_dict()\n","\n","    def load_state_dict(self, state_dict):\n","        self.optimizer.load_state_dict(state_dict)\n","\n","    def _backup_and_load_cache(self):\n","        \"\"\"Useful for performing evaluation on the slow weights (which typically generalize better)\n","        \"\"\"\n","        for group in self.optimizer.param_groups:\n","            for p in group['params']:\n","                param_state = self.state[p]\n","                param_state['backup_params'] = torch.zeros_like(p.data)\n","                param_state['backup_params'].copy_(p.data)\n","                p.data.copy_(param_state['cached_params'])\n","\n","    def _clear_and_load_backup(self):\n","        for group in self.optimizer.param_groups:\n","            for p in group['params']:\n","                param_state = self.state[p]\n","                p.data.copy_(param_state['backup_params'])\n","                del param_state['backup_params']\n","\n","    def step(self, closure=None):\n","        \"\"\"Performs a single Lookahead optimization step.\n","        Arguments:\n","            closure (callable, optional): A closure that reevaluates the model\n","                and returns the loss.\n","        \"\"\"\n","        loss = self.optimizer.step(closure)\n","        self.step_counter += 1\n","\n","        if self.step_counter >= self.k:\n","            self.step_counter = 0\n","            # Lookahead and cache the current optimizer parameters\n","            for group in self.optimizer.param_groups:\n","                for p in group['params']:\n","                    param_state = self.state[p]\n","                    p.data.mul_(self.alpha).add_(1.0 - self.alpha, param_state['cached_params'])  # crucial line\n","                    param_state['cached_params'].copy_(p.data)\n","                    if self.pullback_momentum == \"pullback\":\n","                        internal_momentum = self.optimizer.state[p][\"momentum_buffer\"]\n","                        self.optimizer.state[p][\"momentum_buffer\"] = internal_momentum.mul_(self.alpha).add_(\n","                            1.0 - self.alpha, param_state[\"cached_mom\"])\n","                        param_state[\"cached_mom\"] = self.optimizer.state[p][\"momentum_buffer\"]\n","                    elif self.pullback_momentum == \"reset\":\n","                        self.optimizer.state[p][\"momentum_buffer\"] = torch.zeros_like(p.data)\n","\n","        return loss"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"2MVRebu8WOjz","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598965651318,"user_tz":-180,"elapsed":25282,"user":{"displayName":"Kirill Romanov","photoUrl":"","userId":"02666825069423801309"}}},"source":["class RAdam(Optimizer):\n","\n","    def __init__(self, params, lr=1e-3, betas=(0.9, 0.999), eps=1e-8, weight_decay=0, degenerated_to_sgd=True):\n","        if not 0.0 <= lr:\n","            raise ValueError(\"Invalid learning rate: {}\".format(lr))\n","        if not 0.0 <= eps:\n","            raise ValueError(\"Invalid epsilon value: {}\".format(eps))\n","        if not 0.0 <= betas[0] < 1.0:\n","            raise ValueError(\"Invalid beta parameter at index 0: {}\".format(betas[0]))\n","        if not 0.0 <= betas[1] < 1.0:\n","            raise ValueError(\"Invalid beta parameter at index 1: {}\".format(betas[1]))\n","        \n","        self.degenerated_to_sgd = degenerated_to_sgd\n","        if isinstance(params, (list, tuple)) and len(params) > 0 and isinstance(params[0], dict):\n","            for param in params:\n","                if 'betas' in param and (param['betas'][0] != betas[0] or param['betas'][1] != betas[1]):\n","                    param['buffer'] = [[None, None, None] for _ in range(10)]\n","        defaults = dict(lr=lr, betas=betas, eps=eps, weight_decay=weight_decay, buffer=[[None, None, None] for _ in range(10)])\n","        super(RAdam, self).__init__(params, defaults)\n","\n","    def __setstate__(self, state):\n","        super(RAdam, self).__setstate__(state)\n","\n","    def step(self, closure=None):\n","\n","        loss = None\n","        if closure is not None:\n","            loss = closure()\n","\n","        for group in self.param_groups:\n","\n","            for p in group['params']:\n","                if p.grad is None:\n","                    continue\n","                grad = p.grad.data.float()\n","                if grad.is_sparse:\n","                    raise RuntimeError('RAdam does not support sparse gradients')\n","\n","                p_data_fp32 = p.data.float()\n","\n","                state = self.state[p]\n","\n","                if len(state) == 0:\n","                    state['step'] = 0\n","                    state['exp_avg'] = torch.zeros_like(p_data_fp32)\n","                    state['exp_avg_sq'] = torch.zeros_like(p_data_fp32)\n","                else:\n","                    state['exp_avg'] = state['exp_avg'].type_as(p_data_fp32)\n","                    state['exp_avg_sq'] = state['exp_avg_sq'].type_as(p_data_fp32)\n","\n","                exp_avg, exp_avg_sq = state['exp_avg'], state['exp_avg_sq']\n","                beta1, beta2 = group['betas']\n","\n","                exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n","                exp_avg.mul_(beta1).add_(1 - beta1, grad)\n","\n","                state['step'] += 1\n","                buffered = group['buffer'][int(state['step'] % 10)]\n","                if state['step'] == buffered[0]:\n","                    N_sma, step_size = buffered[1], buffered[2]\n","                else:\n","                    buffered[0] = state['step']\n","                    beta2_t = beta2 ** state['step']\n","                    N_sma_max = 2 / (1 - beta2) - 1\n","                    N_sma = N_sma_max - 2 * state['step'] * beta2_t / (1 - beta2_t)\n","                    buffered[1] = N_sma\n","\n","                    # more conservative since it's an approximated value\n","                    if N_sma >= 5:\n","                        step_size = math.sqrt((1 - beta2_t) * (N_sma - 4) / (N_sma_max - 4) * (N_sma - 2) / N_sma * N_sma_max / (N_sma_max - 2)) / (1 - beta1 ** state['step'])\n","                    elif self.degenerated_to_sgd:\n","                        step_size = 1.0 / (1 - beta1 ** state['step'])\n","                    else:\n","                        step_size = -1\n","                    buffered[2] = step_size\n","\n","                # more conservative since it's an approximated value\n","                if N_sma >= 5:\n","                    if group['weight_decay'] != 0:\n","                        p_data_fp32.add_(-group['weight_decay'] * group['lr'], p_data_fp32)\n","                    denom = exp_avg_sq.sqrt().add_(group['eps'])\n","                    p_data_fp32.addcdiv_(-step_size * group['lr'], exp_avg, denom)\n","                    p.data.copy_(p_data_fp32)\n","                elif step_size > 0:\n","                    if group['weight_decay'] != 0:\n","                        p_data_fp32.add_(-group['weight_decay'] * group['lr'], p_data_fp32)\n","                    p_data_fp32.add_(-step_size * group['lr'], exp_avg)\n","                    p.data.copy_(p_data_fp32)\n","\n","        return loss\n"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"hLxOpS7zTYjU","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598965651318,"user_tz":-180,"elapsed":22846,"user":{"displayName":"Kirill Romanov","photoUrl":"","userId":"02666825069423801309"}}},"source":["class GPT2Preprocessor:\n","    def __init__(self, transformer_tokenizer, sentence_detector):\n","        self.transformer_tokenizer = transformer_tokenizer\n","        self.sentence_detector = sentence_detector\n","\n","    def add_eos_tokens(self, text):\n","        eos_token = \" \" + self.transformer_tokenizer.eos_token + \" \"\n","        sentences = self.sentence_detector.tokenize(text)\n","        eos_added_text = (\n","            eos_token.join(sentences) + \" \" + self.transformer_tokenizer.eos_token\n","        )\n","        return eos_added_text"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"-RPZ4y7WfBAx","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598965651319,"user_tz":-180,"elapsed":22508,"user":{"displayName":"Kirill Romanov","photoUrl":"","userId":"02666825069423801309"}}},"source":["class Vectorizer():\n","    def __init__(self,tokenizer: Callable, max_seq_len: int):\n","        \"\"\"\n","        Args:\n","            tokenizer (Callable): transformer tokenizer\n","            max_seq_len (int): Maximum sequence lenght \n","        \"\"\"\n","        self.tokenizer = tokenizer\n","        self._max_seq_len = max_seq_len\n","\n","    def vectorize(self,text :str):\n","        sequence = \\\n","            self.tokenizer.prepare_for_tokenization(text,add_prefix_space=True)[0]\n","        indices = self.tokenizer.encode(sequence)\n","        \n","        out_vector = np.zeros(self._max_seq_len, dtype=np.int64)\n","        out_vector[: len(indices)] = indices\n","        # max len is restricted to 1024\n","        return out_vector[:min(self._max_seq_len,1024)]        "],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"pjvpg4_vXi86","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598965651320,"user_tz":-180,"elapsed":22323,"user":{"displayName":"Kirill Romanov","photoUrl":"","userId":"02666825069423801309"}}},"source":["class FakeDataset(Dataset):\n","    def __init__(self, data_df: pd.DataFrame, \n","                 tokenizer: Callable, max_len:int=None):\n","        \"\"\"\n","        Args:\n","            data_df (pandas.DataFrame): df containing the labels and text\n","            tokenizer (tokenizer module for the transformer)\n","        \"\"\"\n","        self.data_df = data_df\n","        self.tokenizer = tokenizer\n","\n","        # measure_len = lambda context: len(context.split(\" \"))\n","        # self._max_seq_length = max(map(measure_len, data_df.text)) + 2\n","        if max_len == None:\n","            self._max_seq_length = self._get_max_len(data_df,tokenizer)\n","        else:\n","            self._max_seq_length = max_len\n","\n","        self.train_df = self.data_df[self.data_df.split == 'train']\n","        self.train_size = len(self.train_df)\n","        print(\"Train size\", self.train_size)\n","\n","        self.val_df = self.data_df[self.data_df.split == 'val']\n","        self.val_size = len(self.val_df)\n","        print(\"Val size\", self.val_size)\n","\n","        self.test_df = self.data_df[self.data_df.split == 'test']\n","        self.test_size = len(self.test_df)\n","        print(\"Test size\", self.test_size)\n","\n","\n","        self._vectorizer = Vectorizer(tokenizer, self._max_seq_length)\n","\n","\n","        self._lookup_dict = {\n","            'train': (self.train_df, self.train_size),\n","            'val': (self.val_df, self.val_size),\n","            'test': (self.test_df, self.test_size)\n","        }\n","\n","        self.set_split('train')\n","\n","        class_counts = data_df.label.value_counts().to_dict()\n","         #sorted on the basis of class label,eg, 0,1,2..\n","        cts = sorted([(lbl,cts) for lbl,cts in class_counts.items()], key=lambda x: x[0])\n","        freq = [ x[1] for x in cts ]\n","        # print(freq,cts)\n","        self.class_weights = 1.0/ torch.tensor(freq, dtype=torch.float32)\n","    \n","    def _get_max_len(self, data_df: pd.DataFrame, tokenizer: Callable):\n","        prep_func = lambda x: self.tokenizer.prepare_for_tokenization(x, add_prefix_space=True)\n","        len_func = lambda x: len(prep_func(x))\n","        all_len = data_df.text.map(len_func)\n","        print(all_len)\n","        max_len = all_len.max()\n","        return max_len\n","    \n","\n","    def set_split(self, split=\"train\"):\n","        \"\"\" selects the splits in the dataset using a column in the dataframe \"\"\"\n","        self._target_split = split\n","        self._target_df, self._target_size = self._lookup_dict[split]\n","    \n","    def __len__(self):\n","        return self._target_size\n","    \n","    def __getitem__(self, index):\n","        \"\"\"the primary entry point method for PyTorch datasets\n","        \n","        Args:\n","            index (int): the index to the data point \n","        Returns:\n","            a dictionary holding the data point's features (x_data) and label (y_target)\n","        \"\"\"\n","        row = self._target_df.iloc[index]\n","\n","        sequence = self._vectorizer.vectorize(row.text)\n","\n","        label = row.label\n","        return {'x_data': sequence,\n","                'x_index': index,\n","                'y_target': label}\n","    \n","    def get_num_batches(self, batch_size):\n","        \"\"\"Given a batch size, return the number of batches in the dataset\n","        \n","        Args:\n","            batch_size (int)\n","        Returns:\n","            number of batches in the dataset\n","        \"\"\"\n","        return len(self) // batch_size"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"0R2yLECbfj3Y","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598965652310,"user_tz":-180,"elapsed":979,"user":{"displayName":"Kirill Romanov","photoUrl":"","userId":"02666825069423801309"}}},"source":["def generate_batches(dataset, batch_size, shuffle=True,\n","                     drop_last=False, device=\"cpu\", pinned_memory = False, \n","                     n_workers = 0): \n","    \"\"\"\n","    A generator function which wraps the PyTorch DataLoader. It will \n","      ensure each tensor is on the write device location.\n","    \"\"\"\n","    dataloader = DataLoader(dataset=dataset, batch_size=batch_size,\n","                            shuffle=shuffle, drop_last=drop_last,\n","                            pin_memory= pinned_memory,\n","                            num_workers = n_workers,\n","                            )\n","    \n","    for data_dict in dataloader:\n","        out_data_dict = {}\n","        out_data_dict['x_data'] = data_dict['x_data'].to(\n","            device, non_blocking= (True if pinned_memory else False) \n","        )\n","        # out_data_dict['x_attn_mask'] = data_dict['x_attn_mask'].to(\n","        #     device, non_blocking= (True if pinned_memory else False) \n","        # )\n","        out_data_dict['x_index'] = data_dict['x_index']\n","        out_data_dict['y_target'] = data_dict['y_target'].to(\n","            device, non_blocking= (True if pinned_memory else False) \n","        )\n","        yield out_data_dict"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"2RkcXCHSph1_","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598965652312,"user_tz":-180,"elapsed":972,"user":{"displayName":"Kirill Romanov","photoUrl":"","userId":"02666825069423801309"}}},"source":["class SimpleGPT2SequenceClassifier(nn.Module):\n","    def __init__(\n","        self, \n","        hidden_size: int,\n","        num_classes:int ,\n","        max_seq_len:int,\n","        gpt_model_name:str, \n","    ):\n","        super(SimpleGPT2SequenceClassifier,self).__init__()\n","        self.gpt2model = GPT2Model.from_pretrained(\n","            gpt_model_name\n","        )\n","        self.fc1 = nn.Linear(hidden_size, num_classes)\n","        \n","    def forward(self, x_in):\n","        \n","        gpt_out = self.gpt2model(x_in)[0] #returns tuple\n","        batch_size = gpt_out.shape[0]\n","        prediction_vector = self.fc1(gpt_out.view(batch_size,-1)) #(batch_size , max_len, num_classes)\n","    \n","        return prediction_vector"],"execution_count":13,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6NicJKhWkl-i","colab_type":"text"},"source":["## Set arguments"]},{"cell_type":"code","metadata":{"id":"4dnT8a0UgxHr","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598965754328,"user_tz":-180,"elapsed":797,"user":{"displayName":"Kirill Romanov","photoUrl":"","userId":"02666825069423801309"}}},"source":["args = Namespace(\n","        #use cuda by default\n","        device = 'cuda' if torch.cuda.is_available() else 'cpu',\n","\n","    \n","        #set batch size and number of epochs\n","        batch_size = 20,\n","        num_epochs = 10,\n","    \n","        #set the learning rate\n","        learning_rate = 0.0001,\n","\n","        #directory to save our models at\n","        directory = '/content/drive/My Drive/fnews/gpt2/', \n","        model_name = 'GPT2.pt',\n","\n","        # data folder\n","        source_folder = 'data'\n",")"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"E9VVkU9UkzJ7","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598965652641,"user_tz":-180,"elapsed":1292,"user":{"displayName":"Kirill Romanov","photoUrl":"","userId":"02666825069423801309"}}},"source":["set_seed_everywhere()"],"execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8WIou_wmkqOf","colab_type":"text"},"source":["## Load and preprocess data"]},{"cell_type":"code","metadata":{"id":"pnEPEbMqkJXy","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":359},"executionInfo":{"status":"ok","timestamp":1598965760082,"user_tz":-180,"elapsed":3012,"user":{"displayName":"Kirill Romanov","photoUrl":"","userId":"02666825069423801309"}},"outputId":"9cd0e09c-65d4-4e60-d201-61e169c18e80"},"source":["train_df = pd.read_csv(os.path.join(args.source_folder, 'train.csv'))\n","train_df[\"label\"] = train_df.label.replace({\"real\": 0 , \"fake\": 1})\n","# train_df['text'] = train_df['text'].apply(trim_string)\n","val_df = pd.read_csv(os.path.join(args.source_folder, 'val.csv'))\n","val_df[\"label\"] = val_df.label.replace({\"real\": 0 , \"fake\": 1})\n","# val_df['text'] = val_df['text'].apply(trim_string)\n","train_val = pd.concat([train_df, val_df])\n","\n","train, val = train_test_split(train_val, stratify=train_val.label, test_size=0.05) \n","train, test = train_test_split(train, stratify=train.label, test_size=0.05)\n","train_val.loc[train.index, 'split'] = \"train\"\n","train_val.loc[val.index, 'split'] = \"val\"\n","train_val.loc[test.index, 'split'] = \"test\"\n","\n","del train_df, val_df, train, val, test\n","gc.collect()\n","\n","train_val.head(10)"],"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>label</th>\n","      <th>split</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>The court granted by a 5-4 vote a request made...</td>\n","      <td>0</td>\n","      <td>train</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>\" Pennsylvania was a crucial swing state in th...</td>\n","      <td>0</td>\n","      <td>train</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>The company today is rolling out an update to ...</td>\n","      <td>1</td>\n","      <td>train</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>When it comes to trade policy, Hillary Clinton...</td>\n","      <td>0</td>\n","      <td>train</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>S. stocks had their worst April start since 19...</td>\n","      <td>0</td>\n","      <td>train</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Journey Energy Inc * Journey Energy, Inc. (NAS...</td>\n","      <td>1</td>\n","      <td>train</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>Lights like the lights on the back of Alcatel'...</td>\n","      <td>0</td>\n","      <td>train</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>Chief Cabinet Secretary Yoshihide Suga said th...</td>\n","      <td>0</td>\n","      <td>train</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>(Adds quotes, details) AMSTERDAM, Dec 7 (Reute...</td>\n","      <td>0</td>\n","      <td>train</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>Feb 24 (Reuters) - Danske Andelskassers Bank A...</td>\n","      <td>0</td>\n","      <td>train</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                text  label  split\n","0  The court granted by a 5-4 vote a request made...      0  train\n","1  \" Pennsylvania was a crucial swing state in th...      0  train\n","2  The company today is rolling out an update to ...      1  train\n","3  When it comes to trade policy, Hillary Clinton...      0  train\n","4  S. stocks had their worst April start since 19...      0  train\n","5  Journey Energy Inc * Journey Energy, Inc. (NAS...      1  train\n","6  Lights like the lights on the back of Alcatel'...      0  train\n","7  Chief Cabinet Secretary Yoshihide Suga said th...      0  train\n","8  (Adds quotes, details) AMSTERDAM, Dec 7 (Reute...      0  train\n","9  Feb 24 (Reuters) - Danske Andelskassers Bank A...      0  train"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"markdown","metadata":{"id":"gLMIkhUJlBDf","colab_type":"text"},"source":["## Tokenize data and create dataset"]},{"cell_type":"code","metadata":{"id":"FQ4z23Qck5r3","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":117,"referenced_widgets":["d0ecdc25452544b296cb5062723a030d","ad88bb350eec448489c554067d81168f","aeaaa422f6c3442fbd40fc071bbec564","8a6b8d5dd3764da8900e606521bf90f6","9fd2d6872d3d4fb98f8141e4d3220fe5","924ed7f5b932474388068511259e381d","a7c8d30eb7714a13baf7d9eb098ae3c1","3d79ee0e48014498ba396ba162bdaa18","f335cd5cb59c4ab897131933beae8df0","864e4a290a34474882d714e66940a22f","47d5b0275a4d4ecc8edeff2b426cedd7","169c0b84954d4d75a36ea3aa29bbc9ad","13330e9d481b43cab5709e4841f5c9a4","8e941aaf88dc4ac18c6d4de7478c1e29","61b419501e1743dea14e1ae457dcfc0f","ff5b7801c78b46f9ba3301e7c358ed8e"]},"executionInfo":{"status":"ok","timestamp":1598965670861,"user_tz":-180,"elapsed":5924,"user":{"displayName":"Kirill Romanov","photoUrl":"","userId":"02666825069423801309"}},"outputId":"490a4003-7d98-4911-9ae7-8ed6f1ca09c6"},"source":["gpt2_tokenizer = GPT2Tokenizer.from_pretrained(\"distilgpt2\")\n","punkt_sentence_detector = nltk.data.load('tokenizers/punkt/english.pickle')\n","gpt2_preproc = GPT2Preprocessor(gpt2_tokenizer, punkt_sentence_detector)"],"execution_count":15,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d0ecdc25452544b296cb5062723a030d","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1042301.0, style=ProgressStyle(descript…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f335cd5cb59c4ab897131933beae8df0","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456318.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"R2Uf30SUs_50","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":71},"executionInfo":{"status":"ok","timestamp":1598965785849,"user_tz":-180,"elapsed":22399,"user":{"displayName":"Kirill Romanov","photoUrl":"","userId":"02666825069423801309"}},"outputId":"5d61d3e5-eb2c-4364-edbc-90e32a2c038d"},"source":["train_val[\"text\"] = train_val[\"text\"].map(gpt2_preproc.add_eos_tokens)\n","dataset = FakeDataset(data_df=train_val, tokenizer=gpt2_tokenizer, max_len=512)"],"execution_count":23,"outputs":[{"output_type":"stream","text":["Train size 237483\n","Val size 16853\n","Test size 16333\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Wo5cBB5ylQVA","colab_type":"text"},"source":["## Create model and optimizer"]},{"cell_type":"code","metadata":{"id":"0I-s1Dwjk5vb","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["162456781407482c98f51a95a516b43d","767fd00910bd40e0b5824492b37450d5","5d15fb4ebce84d45b20ae347cd9a9ff3","c31b17cad3bd4a9abfc920140a538cd9","e264fdae8fde4440ad16eeabe4c71c21","eb9f86329089493a8c356852e80ab155","842a2b19cd3f4572a4fc5aa29d018bbf","d62d5834f5144a10b30ed116a9429687","2674121b3604426cbcdfb20dc10386f3","7341fac71f6644ff9bb5ab1ccfa5dca9","d97454a1701a4b5f9b06680840ef9bf0","11ecd549a12c4898ba725adab7a485fb","3f3e5a6bc0d54828b3c6aa663919e9f8","959478cfa5864be6ab0b0bb366defce8","060ea4949fed42768a3fce08fc4c8d46","29513c34feec4529b8828addd3c9e753"]},"executionInfo":{"status":"ok","timestamp":1598965807339,"user_tz":-180,"elapsed":41098,"user":{"displayName":"Kirill Romanov","photoUrl":"","userId":"02666825069423801309"}},"outputId":"66e35a8c-d686-4afd-e009-4fa76ebc364c"},"source":["num_classes = len(set(train_val.label))\n","hidden_size = dataset._max_seq_length * 768\n","model = SimpleGPT2SequenceClassifier(\n","    hidden_size=hidden_size,\n","    num_classes=num_classes,\n","    gpt_model_name=\"distilgpt2\",\n","    max_seq_len=dataset._max_seq_length,\n",")\n","model.to(args.device)"],"execution_count":24,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"162456781407482c98f51a95a516b43d","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=762.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2674121b3604426cbcdfb20dc10386f3","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=352833716.0, style=ProgressStyle(descri…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of GPT2Model were not initialized from the model checkpoint at distilgpt2 and are newly initialized: ['transformer.h.0.attn.masked_bias', 'transformer.h.1.attn.masked_bias', 'transformer.h.2.attn.masked_bias', 'transformer.h.3.attn.masked_bias', 'transformer.h.4.attn.masked_bias', 'transformer.h.5.attn.masked_bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["SimpleGPT2SequenceClassifier(\n","  (gpt2model): GPT2Model(\n","    (wte): Embedding(50257, 768)\n","    (wpe): Embedding(1024, 768)\n","    (drop): Dropout(p=0.1, inplace=False)\n","    (h): ModuleList(\n","      (0): Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (1): Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (2): Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (3): Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (4): Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (5): Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","    )\n","    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","  )\n","  (fc1): Linear(in_features=393216, out_features=2, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"code","metadata":{"id":"AF17w1JxoWTE","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1598910629834,"user_tz":-180,"elapsed":529,"user":{"displayName":"Kirill Romanov","photoUrl":"","userId":"02666825069423801309"}},"outputId":"86c1588f-5ccf-4f7c-d62d-e6e98a8f9fcb"},"source":["loss_func = nn.CrossEntropyLoss()\n","base_optimizer = RAdam(model.parameters(), lr=args.learning_rate)\n","optimizer = Lookahead(optimizer=base_optimizer, k=5, alpha=0.5)\n","print(f\"Using LR:{args.learning_rate}\")"],"execution_count":52,"outputs":[{"output_type":"stream","text":["Using LR:0.0001\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Qwh6dTS2hKVI","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598910636139,"user_tz":-180,"elapsed":544,"user":{"displayName":"Kirill Romanov","photoUrl":"","userId":"02666825069423801309"}}},"source":["train_state = make_train_state()\n","train_state[\"ckpt\"] = 0\n","train_state['max_seq_len'] = dataset._max_seq_length\n","early_stopping = EarlyStopping(patience=5)"],"execution_count":53,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kKy7feW8lgGq","colab_type":"text"},"source":["## Training"]},{"cell_type":"code","metadata":{"id":"pi_sLwFfii7M","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":501,"referenced_widgets":["8d46302640d948548435b669f05ac342","36d760197854495b8427bec29bd60319","b232b45f6a5841fea240858f2bea1ced","36f4c87de1ca4d338677e7d9c2a80587","2c33f8161a21417cbc86f212e0565370","1c473249eb3e43a185538a9196974a85","108ae0e414e5477a872f83643216005d","94c0e1dfff7d41848e415e8eafb6d933","7ffdaf4c6f2747c3a1925bad5b93ef15","081cf510f0c4469aaf8af68fd8dff6be","ac924148914f4be1a20aa5c50455839d","1247334d9c954a0e933144629aac3aec","61771ea31cef4d369417925b9934d37b","c78793f21e9f40dda839dcb1f301f104","8245ffd58707474594ef6b5f95bf6228","abd596bc5162405b81c97d07d498b308","389e8a2a6604476ab40e04742926a87b","ad042a20ef834759ad5c56539d5bfab3","8adf686c94fb491ab57c3d3b04f87287","f4bbbd2b56dd4b15b8d71d7b5d451d9b","326062b079ce4e88ac79fb5c604fcc45","da4940e64565470ea1b08ddf88189d2c","44f92540cfd544a2be3661685e373f7a","eeaef2ed0b6f4d1aa67401cebf7a0720"]},"executionInfo":{"status":"error","timestamp":1598957529221,"user_tz":-180,"elapsed":3222079,"user":{"displayName":"Kirill Romanov","photoUrl":"","userId":"02666825069423801309"}},"outputId":"995c509c-0dc2-4208-cdc7-6208966f1abc"},"source":["epoch_bar = notebook.tqdm(\n","    desc = 'training_routine',\n","    total = args.num_epochs,\n","    position=0,\n","    leave = True,\n",")\n","dataset.set_split('train')\n","train_bar = notebook.tqdm(\n","    desc = 'split=train ',\n","    total=dataset.get_num_batches(args.batch_size),\n","    position=0,\n","    leave=True,\n",")\n","dataset.set_split('val')\n","eval_bar = notebook.tqdm(\n","    desc = 'split=eval',\n","    total=dataset.get_num_batches(args.batch_size),\n","    position=0,\n","    leave=True,\n",")\n","\n","\n","for epoch_index in range(args.num_epochs):\n","    train_state['epoch_in'] = epoch_index\n","\n","    dataset.set_split('train')\n","    batch_generator = generate_batches(\n","        dataset=dataset,\n","        batch_size=args.batch_size,\n","        shuffle=True,\n","        device=args.device,\n","        drop_last=False,\n","    )\n","\n","\n","    running_loss = 0.0\n","    running_acc = 0.0\n","    running_f1 = 0.0\n","    model.train()\n","\n","    train_bar.reset(\n","        total=dataset.get_num_batches(args.batch_size),\n","    )\n","    # print(f\"Train for total {dataset.get_num_batches(args.batch_size)} batches\")\n","    update_every = int(dataset.get_num_batches(args.batch_size)/100)\n","    model.train()\n","    for batch_index, batch_dict in enumerate(batch_generator):\n","        optimizer.zero_grad()\n","        \n","        y_pred = model(batch_dict[\"x_data\"])\n","\n","        loss = loss_func(y_pred, batch_dict[\"y_target\"])\n","        loss_t = loss.item()\n","\n","\n","        loss.backward()\n","        optimizer.step()\n","                             \n","        loss_t = loss.item()\n","        running_loss += (loss_t - running_loss) / (batch_index + 1)\n","\n","                             \n","        y_pred = y_pred.detach().cpu()\n","\n","        batch_dict['y_target'] = batch_dict['y_target'].cpu()\n","        \n","        acc_t = compute_accuracy(\n","            y_pred, batch_dict[\"y_target\"]\n","        )\n","\n","        f1_t = compute_macro_f1(\n","            y_pred, batch_dict[\"y_target\"]\n","        )\n","\n","        train_state[\"batch_preds\"].append(y_pred)\n","        train_state[\"batch_targets\"].append(batch_dict[\"y_target\"])\n","        train_state[\"batch_indexes\"].append(batch_dict[\"x_index\"])\n","\n","        running_acc += (acc_t - running_acc) / (batch_index + 1)\n","        running_f1 += (f1_t - running_f1) / (batch_index + 1)\n","\n","        if batch_index % update_every == 0:\n","          train_bar.set_postfix(loss = running_loss, f1 = running_f1, \n","                                acc=running_acc, epoch=epoch_index)\n","          if batch_index > 0:\n","            train_bar.update(update_every)\n","          else:\n","            train_bar.update()\n","    \n","    train_bar.set_postfix(loss = running_loss, f1 = running_f1, \n","                                acc=running_acc, epoch=epoch_index)\n","    train_bar.update(dataset.get_num_batches(args.batch_size) % update_every)\n","\n","    if torch.cuda.is_available():\n","        torch.cuda.empty_cache()\n","    \n","    train_state['train_accuracies'].append(running_acc)\n","    train_state['train_losses'].append(running_loss)\n","    \n","    train_state['train_preds'].append(\n","        torch.cat(train_state['batch_preds']).cpu()\n","    )\n","    train_state['train_targets'].append(\n","        torch.cat(train_state['batch_targets']).cpu()\n","    )\n","    train_state['train_indexes'].append(\n","        torch.cat(train_state['batch_indexes']).cpu()\n","    )\n","    train_f1 = compute_macro_f1(train_state['train_preds'][-1],\n","                                  train_state['train_targets'][-1],\n","                                 )\n","                                 \n","    train_state['train_f1s'].append(train_f1)\n","    \n","    train_state['batch_preds'] = []\n","    train_state['batch_targets'] = []\n","    train_state['batch_indexes'] = []\n","    \n","    \n","    dataset.set_split('val')\n","    batch_generator = generate_batches(\n","        dataset= dataset, batch_size= args.batch_size, shuffle=True,\n","        device = args.device, drop_last=False,\n","        pinned_memory = False, n_workers = 2, \n","    )\n","    eval_bar.reset(\n","        total=dataset.get_num_batches(args.batch_size),\n","    )\n","    running_loss = 0.0\n","    running_acc = 0.0\n","    running_f1 = 0.0\n","\n","    update_every = max(1, int(dataset.get_num_batches(args.batch_size)/100))\n","    \n","    model.eval()\n","    with torch.no_grad():\n","        optimizer._backup_and_load_cache()\n","        for batch_index, batch_dict in enumerate(batch_generator):\n","            y_pred = model(batch_dict[\"x_data\"])\n","\n","            loss = loss_func(y_pred, batch_dict[\"y_target\"])\n","            loss_t = loss.item()\n","\n","            running_loss += (loss_t - running_loss) / (batch_index + 1)\n","\n","            y_pred = y_pred.detach()\n","            \n","            acc_t = compute_accuracy(\n","                y_pred, batch_dict[\"y_target\"]\n","            )\n","\n","            f1_t = compute_macro_f1(\n","                y_pred, batch_dict[\"y_target\"]\n","            )\n","\n","            train_state['batch_preds'].append(y_pred.cpu())\n","            train_state['batch_targets'].append(batch_dict['y_target'])\n","            train_state['batch_indexes'].append(batch_dict['x_index'].cpu())\n","\n","            running_acc += (acc_t - running_acc) / (batch_index + 1)\n","            running_f1 += (f1_t - running_f1) / (batch_index + 1)\n","            \n","            if batch_index % update_every == 0:\n","              eval_bar.set_postfix(loss = running_loss, f1 = running_f1, \n","                                   acc=running_acc, epoch=epoch_index)\n","              if batch_index > 0:\n","                eval_bar.update(update_every)\n","              else:\n","                eval_bar.update()\n","    \n","    \n","    eval_bar.set_postfix(loss = running_loss, f1 = running_f1, acc=running_acc,\n","                                 epoch=epoch_index)\n","    eval_bar.update(dataset.get_num_batches(args.batch_size) % update_every) \n","            \n","    train_state['val_accuracies'].append(running_acc)\n","    train_state['val_losses'].append(running_loss)\n","    \n","        \n","    train_state['val_preds'].append(\n","        torch.cat(train_state['batch_preds']).cpu()\n","    )\n","\n","    train_state['val_targets'].append(\n","        torch.cat(train_state['batch_targets']).cpu()\n","    )\n","\n","    train_state['val_indexes'].append(\n","        torch.cat(train_state['batch_indexes']).cpu()\n","    )\n","\n","    val_f1 = compute_macro_f1(train_state['val_preds'][-1],\n","                                  train_state['val_targets'][-1],\n","                                 )\n","          \n","    train_state['val_f1s'].append(val_f1)\n","    \n","    train_state['batch_preds'] = []\n","    train_state['batch_targets'] = []\n","    train_state['batch_indexes'] = []\n","    \n","    torch.save(\n","        {\n","         'model':model.state_dict(),\n","         'train_preds': train_state['train_preds'][epoch_index],\n","         'train_targets': train_state['train_targets'][epoch_index],\n","         'train_indexes': train_state['train_indexes'][epoch_index],\n","         'train_f1s': train_f1,\n","         'val_preds': train_state['val_preds'][epoch_index],\n","         'val_targets': train_state['val_targets'][epoch_index],\n","         'val_indexes': train_state['val_indexes'][epoch_index],\n","         'val_f1s': val_f1\n","\n","        },\n","        args.directory + f'epoch_{epoch_index}_' + args.model_name,\n","    )\n","    \n","    early_stopping(val_f1, model)\n","    optimizer._clear_and_load_backup()\n","    epoch_bar.set_postfix(best_f1 = early_stopping.best_score, current = val_f1)\n","    epoch_bar.update()"],"execution_count":59,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8d46302640d948548435b669f05ac342","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='training_routine', max=10.0, style=ProgressStyle(descript…"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7ffdaf4c6f2747c3a1925bad5b93ef15","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='split=train ', max=11874.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"389e8a2a6604476ab40e04742926a87b","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='split=eval', max=842.0, style=ProgressStyle(description_w…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:54: UserWarning: This overload of addcmul_ is deprecated:\n","\taddcmul_(Number value, Tensor tensor1, Tensor tensor2)\n","Consider using one of the following signatures instead:\n","\taddcmul_(Tensor tensor1, Tensor tensor2, *, Number value) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:766.)\n"],"name":"stderr"},{"output_type":"stream","text":["EarlyStopping counter: 1 out of 5\n","EarlyStopping counter: 1 out of 5\n","EarlyStopping counter: 2 out of 5\n","EarlyStopping counter: 3 out of 5\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-59-df5f83010eab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"y_target\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mloss_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"fuJdzCtwHaN-","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":55},"executionInfo":{"status":"ok","timestamp":1598957567016,"user_tz":-180,"elapsed":595,"user":{"displayName":"Kirill Romanov","photoUrl":"","userId":"02666825069423801309"}},"outputId":"3a3c28c8-66a3-4784-96b5-ea8efed67f27"},"source":["print(train_state['train_f1s'])"],"execution_count":60,"outputs":[{"output_type":"stream","text":["[0.9959347894945416, 0.995458701452652, 0.9970490392197928, 0.9976985277666942, 0.9982355151956523, 0.9986139605622262, 0.9988594288962278]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wROx2zERGhOU","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":55},"executionInfo":{"status":"ok","timestamp":1598957589680,"user_tz":-180,"elapsed":522,"user":{"displayName":"Kirill Romanov","photoUrl":"","userId":"02666825069423801309"}},"outputId":"6123e144-c6d5-4ee4-cf98-1d5b871f48dc"},"source":["print(train_state['val_f1s'])"],"execution_count":61,"outputs":[{"output_type":"stream","text":["[0.9943194758892655, 0.9932526360677064, 0.996041392214148, 0.9947509081002074, 0.9958221890735273, 0.9952533893242368, 0.9963217291289445]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"g8h0wEfFTJJE","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":359},"executionInfo":{"status":"ok","timestamp":1598957611008,"user_tz":-180,"elapsed":814,"user":{"displayName":"Kirill Romanov","photoUrl":"","userId":"02666825069423801309"}},"outputId":"8c26b7ab-be86-451f-cc9c-f138fb639447"},"source":["best_run_index = train_state['val_f1s'].index(max(train_state['val_f1s']))\n","print(f'Best run at epoch {best_run_index}')\n","print('Train:',classification_report(\n","    y_pred=(torch.argmax(train_state['train_preds'][best_run_index],dim=1) ).cpu().long().numpy(),\n","    y_true= train_state['train_targets'][best_run_index].cpu().numpy(), \n","    digits=4)\n",")\n","print('Dev:',classification_report(\n","    y_pred=(torch.argmax(train_state['val_preds'][best_run_index],dim=1) ).cpu().long().numpy(),\n","    y_true= train_state['val_targets'][best_run_index].cpu().numpy(), \n","    digits=4)\n",")"],"execution_count":62,"outputs":[{"output_type":"stream","text":["Best run at epoch 6\n","Train:               precision    recall  f1-score   support\n","\n","           0     0.9993    0.9993    0.9993    168659\n","           1     0.9984    0.9984    0.9984     68824\n","\n","    accuracy                         0.9991    237483\n","   macro avg     0.9989    0.9989    0.9989    237483\n","weighted avg     0.9991    0.9991    0.9991    237483\n","\n","Dev:               precision    recall  f1-score   support\n","\n","           0     0.9981    0.9977    0.9979     11977\n","           1     0.9943    0.9953    0.9948      4876\n","\n","    accuracy                         0.9970     16853\n","   macro avg     0.9962    0.9965    0.9963     16853\n","weighted avg     0.9970    0.9970    0.9970     16853\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"U8buM4lhTOR1","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598957714666,"user_tz":-180,"elapsed":571,"user":{"displayName":"Kirill Romanov","photoUrl":"","userId":"02666825069423801309"}}},"source":["def sort_preds(indexes, preds):\n","    \"\"\"Sorts the predictions in order, to reverse the effects of shuffle\n","    done by dataloader\"\"\"\n","    indexes = indexes.cpu().numpy().reshape(-1,1)\n","    preds = preds.cpu().numpy()\n","    arr_concat = np.hstack((indexes,preds)) #concat the preds and their indexes\n","    sort_arr = arr_concat[ arr_concat[:,0].argsort()] #sort based on the indexes\n","    sorted_preds = np.delete(sort_arr,0,axis=1)\n","    return sorted_preds\n","\n","def get_optimal_models(train_state, split, reverse=False ):\n","    \"\"\"Naive Ensembling\"\"\"\n","    trgts= sort_preds(train_state[f'{split}_indexes'][-1],train_state[f'{split}_targets'][-1].reshape(-1,1))\n","    total_preds = len(train_state[f'{split}_indexes'])\n","    init = np.zeros(train_state[f'{split}_preds'][-1].shape)\n","    max_f1 = 0\n","    idxes = []\n","    rng = range(0,total_preds)\n","    if reverse:\n","        rng = reversed(rng)\n","    for i in rng:\n","        temp = sort_preds(train_state[f'{split}_indexes'][i],train_state[f'{split}_preds'][i])\n","        temp2 = init+temp\n","        f1 = f1_score(\n","            y_pred=temp2.argmax(axis=1),\n","            y_true= trgts, average ='weighted'\n","        )\n","        if f1 > max_f1:\n","            max_f1 = f1\n","            init = init+temp\n","            idxes.append(i)\n","    print(f'Taking preds from {idxes} | Dev f1:{f1}')\n","    return (idxes,max_f1)"],"execution_count":66,"outputs":[]},{"cell_type":"code","metadata":{"id":"6gQoZWkaTdC3","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":71},"executionInfo":{"status":"ok","timestamp":1598957736668,"user_tz":-180,"elapsed":549,"user":{"displayName":"Kirill Romanov","photoUrl":"","userId":"02666825069423801309"}},"outputId":"3c550017-a52a-4c7d-8738-8e746bcd4348"},"source":["best_model_f1_score = f1_score(\n","    y_pred=(torch.argmax(train_state['val_preds'][best_run_index],dim=1) ).cpu().long().numpy(),\n","    y_true= train_state['val_targets'][best_run_index].cpu().numpy(), \n","    average='weighted'\n",")\n","_models= [get_optimal_models(train_state,'val', reverse=False),\n","                 get_optimal_models(train_state,'val', reverse=True),\n","                 ([best_run_index],best_model_f1_score),]\n","optimal_models = max(_models, key=lambda x:x[1]) #select ensembles or best model \n","print(f'Optimal models chosen: {optimal_models}')"],"execution_count":67,"outputs":[{"output_type":"stream","text":["Taking preds from [0, 1, 2, 3, 4, 6] | Dev f1:0.9982211939120201\n","Taking preds from [6, 5, 4, 3, 2, 1] | Dev f1:0.9981028353035498\n","Optimal models chosen: ([0, 1, 2, 3, 4, 6], 0.9982211939120201)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"U-AcX2ItTheY","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":143},"executionInfo":{"status":"ok","timestamp":1598965808530,"user_tz":-180,"elapsed":1180,"user":{"displayName":"Kirill Romanov","photoUrl":"","userId":"02666825069423801309"}},"outputId":"ec7274f2-1e2f-4da5-cdb7-1bf75dca182d"},"source":["all_models= [os.path.join(args.directory,i) for i in os.listdir(args.directory) if args.model_name in i and '-1' not in i]\n","all_models = sorted(all_models, key = lambda x: int(x[41])) #sort by epoch num.\n","all_models"],"execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['/content/drive/My Drive/fnews/gpt2/epoch_0_GPT2.pt',\n"," '/content/drive/My Drive/fnews/gpt2/epoch_1_GPT2.pt',\n"," '/content/drive/My Drive/fnews/gpt2/epoch_2_GPT2.pt',\n"," '/content/drive/My Drive/fnews/gpt2/epoch_3_GPT2.pt',\n"," '/content/drive/My Drive/fnews/gpt2/epoch_4_GPT2.pt',\n"," '/content/drive/My Drive/fnews/gpt2/epoch_5_GPT2.pt',\n"," '/content/drive/My Drive/fnews/gpt2/epoch_6_GPT2.pt']"]},"metadata":{"tags":[]},"execution_count":25}]},{"cell_type":"code","metadata":{"id":"UxvIkfFyTi_E","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":125},"executionInfo":{"status":"ok","timestamp":1598965844158,"user_tz":-180,"elapsed":977,"user":{"displayName":"Kirill Romanov","photoUrl":"","userId":"02666825069423801309"}},"outputId":"d3408821-d30a-430a-c8b1-a7dc4aa357ab"},"source":["optimal_models = [0, 1, 2, 3, 4, 6]\n","selected_models = [all_models[i] for i in optimal_models]\n","pprint.pprint(selected_models)"],"execution_count":27,"outputs":[{"output_type":"stream","text":["['/content/drive/My Drive/fnews/gpt2/epoch_0_GPT2.pt',\n"," '/content/drive/My Drive/fnews/gpt2/epoch_1_GPT2.pt',\n"," '/content/drive/My Drive/fnews/gpt2/epoch_2_GPT2.pt',\n"," '/content/drive/My Drive/fnews/gpt2/epoch_3_GPT2.pt',\n"," '/content/drive/My Drive/fnews/gpt2/epoch_4_GPT2.pt',\n"," '/content/drive/My Drive/fnews/gpt2/epoch_6_GPT2.pt']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"px87SDwoU1hW","colab_type":"text"},"source":["## Loading test set"]},{"cell_type":"code","metadata":{"id":"2AADyJuVT8ab","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598965879475,"user_tz":-180,"elapsed":11559,"user":{"displayName":"Kirill Romanov","photoUrl":"","userId":"02666825069423801309"}}},"source":["test_df = pd.read_csv(os.path.join(args.source_folder, 'test.csv'))\n","test_df[\"label\"] = 0\n","test_df[\"split\"] = 'test'\n","test_df[\"text\"] = test_df[\"text\"].map(gpt2_preproc.add_eos_tokens)"],"execution_count":28,"outputs":[]},{"cell_type":"code","metadata":{"id":"5-_YB98AUEJI","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":419},"executionInfo":{"status":"ok","timestamp":1598965879476,"user_tz":-180,"elapsed":6963,"user":{"displayName":"Kirill Romanov","photoUrl":"","userId":"02666825069423801309"}},"outputId":"cdfc8fa6-f47c-4c40-e449-ded235345f0d"},"source":["test_df"],"execution_count":29,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>label</th>\n","      <th>split</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>We asked for \"disclosure of any information th...</td>\n","      <td>0</td>\n","      <td>test</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Continued disruptions by a range of local grou...</td>\n","      <td>0</td>\n","      <td>test</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Criminal gangs in China are faking outbreaks o...</td>\n","      <td>0</td>\n","      <td>test</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>\"After we announced the Hess transaction, we h...</td>\n","      <td>0</td>\n","      <td>test</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>A Syngenta spokesman clarified his comment ear...</td>\n","      <td>0</td>\n","      <td>test</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>115994</th>\n","      <td>esponse team. &lt;|endoftext|&gt; A unanimous three-...</td>\n","      <td>0</td>\n","      <td>test</td>\n","    </tr>\n","    <tr>\n","      <th>115995</th>\n","      <td>S. market for Singapore Airlines and Malaysia ...</td>\n","      <td>0</td>\n","      <td>test</td>\n","    </tr>\n","    <tr>\n","      <th>115996</th>\n","      <td>The top enforcer of a brutal war on drugs in t...</td>\n","      <td>0</td>\n","      <td>test</td>\n","    </tr>\n","    <tr>\n","      <th>115997</th>\n","      <td>Two South Korean envoys will travel to the Uni...</td>\n","      <td>0</td>\n","      <td>test</td>\n","    </tr>\n","    <tr>\n","      <th>115998</th>\n","      <td>Scope Ratings' structured finance head Guillau...</td>\n","      <td>0</td>\n","      <td>test</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>115999 rows × 3 columns</p>\n","</div>"],"text/plain":["                                                     text  label split\n","0       We asked for \"disclosure of any information th...      0  test\n","1       Continued disruptions by a range of local grou...      0  test\n","2       Criminal gangs in China are faking outbreaks o...      0  test\n","3       \"After we announced the Hess transaction, we h...      0  test\n","4       A Syngenta spokesman clarified his comment ear...      0  test\n","...                                                   ...    ...   ...\n","115994  esponse team. <|endoftext|> A unanimous three-...      0  test\n","115995  S. market for Singapore Airlines and Malaysia ...      0  test\n","115996  The top enforcer of a brutal war on drugs in t...      0  test\n","115997  Two South Korean envoys will travel to the Uni...      0  test\n","115998  Scope Ratings' structured finance head Guillau...      0  test\n","\n","[115999 rows x 3 columns]"]},"metadata":{"tags":[]},"execution_count":29}]},{"cell_type":"code","metadata":{"id":"oKhx5NUtVAGL","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":107},"executionInfo":{"status":"ok","timestamp":1598965887255,"user_tz":-180,"elapsed":1232,"user":{"displayName":"Kirill Romanov","photoUrl":"","userId":"02666825069423801309"}},"outputId":"9b52c09b-e9f9-468d-e217-dcfaab1a577e"},"source":["test_dataset = FakeDataset(data_df=test_df, tokenizer=gpt2_tokenizer, max_len=512)\n","test_dataset.set_split('test')\n","test_dataset._target_df.split.value_counts()"],"execution_count":30,"outputs":[{"output_type":"stream","text":["Train size 0\n","Val size 0\n","Test size 115999\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["test    115999\n","Name: split, dtype: int64"]},"metadata":{"tags":[]},"execution_count":30}]},{"cell_type":"code","metadata":{"id":"mWRqg7suVF4r","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":99,"referenced_widgets":["81805c7f41084f719672ea4990c83984","c6b4c5e473d146288b056438479290b7","e24ae2b08d6041a18d7d8608c089f32d","92cec11d752c43a6aebede9d6a480a1f","d75c558ed0ff4cc7a88f8eb87574984a","f039b40c690c4b79aa655b47eecc9e18","8c5ebad578354148888f80e46de77db5","44b2dca72ce64efe925b593e95163ba9","78918d72c2164a06aa7bf7dd57a95e83","61589b68224f47c989ba5ae43e9f0a85","d42bfb5da79e439da689951eda3d1337","85998eca31ca4fd1b88364d525bb3399","b33896004f7c46a6bb72f6be967ff917","ea557695256a4fd7a4e399e8c650bd87","d8721c97f7e84f5baa8d524aa65b1e53","35ac9638991a49688002c22a694802f2"]},"executionInfo":{"status":"ok","timestamp":1598972936346,"user_tz":-180,"elapsed":7044361,"user":{"displayName":"Kirill Romanov","photoUrl":"","userId":"02666825069423801309"}},"outputId":"30b63489-efe5-4ea8-d71f-49530351917c"},"source":["test_state = make_train_state() \n","test_dataset.set_split('test')\n","eval_bar = notebook.tqdm(\n","    desc = 'split=train ',\n","    total=test_dataset.get_num_batches(args.batch_size),\n","    position=0,\n","    leave=True,\n",")\n","model.eval()\n","for m in notebook.tqdm(selected_models, total=len(selected_models)):\n","    eval_bar.reset(\n","        total=test_dataset.get_num_batches(args.batch_size),\n","    )\n","    update_every = int(test_dataset.get_num_batches(args.batch_size)/100)\n","    model.load_state_dict(torch.load(m)['model'])\n","    batch_generator = generate_batches(\n","        dataset= test_dataset, batch_size= args.batch_size, shuffle=False,\n","        device = args.device, drop_last=False,\n","        pinned_memory = True, n_workers = 1, \n","    )\n","    with torch.no_grad():\n","        for batch_index, batch_dict in enumerate(batch_generator):\n","            y_pred = model(batch_dict[\"x_data\"])\n","\n","            y_pred = y_pred.detach()\n","            \n","            batch_dict['y_target'] = batch_dict['y_target'].cpu()\n","            test_state['batch_preds'].append(y_pred.cpu())\n","            test_state['batch_targets'].append(batch_dict['y_target'].cpu())\n","            test_state['batch_indexes'].append(batch_dict['x_index'].cpu())\n","            \n","            if batch_index % update_every == 0:\n","              if batch_index > 0:\n","                eval_bar.update(update_every)\n","              else:\n","                eval_bar.update()\n","    \n","    eval_bar.update(test_dataset.get_num_batches(args.batch_size) % update_every) \n","    \n","    test_state['val_preds'].append(\n","        torch.cat(test_state['batch_preds']).cpu()\n","    )\n","    test_state['val_targets'].append(\n","        torch.cat(test_state['batch_targets']).cpu()\n","    )\n","    test_state['val_indexes'].append(\n","        torch.cat(test_state['batch_indexes']).cpu()\n","    )\n","    \n","    test_state['batch_preds'] = []\n","    test_state['batch_targets'] = []\n","    test_state['batch_indexes'] = []"],"execution_count":31,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"81805c7f41084f719672ea4990c83984","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='split=train ', max=5799.0, style=ProgressStyle(descriptio…"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"78918d72c2164a06aa7bf7dd57a95e83","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=6.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"83V8l7VRWYoG","colab_type":"text"},"source":["## Add the last layer outputs and apply argmax"]},{"cell_type":"code","metadata":{"id":"ewJ1oNrSWT0U","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598974941129,"user_tz":-180,"elapsed":1006,"user":{"displayName":"Kirill Romanov","photoUrl":"","userId":"02666825069423801309"}}},"source":["ensemble = torch.zeros_like(test_state['val_preds'][-1])\n","for i in test_state['val_preds']:\n","    ensemble += i"],"execution_count":50,"outputs":[]},{"cell_type":"code","metadata":{"id":"phEzUqQPWcTD","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598972953887,"user_tz":-180,"elapsed":1935,"user":{"displayName":"Kirill Romanov","photoUrl":"","userId":"02666825069423801309"}}},"source":["test_preds = torch.argmax(ensemble, dim=1).tolist()"],"execution_count":34,"outputs":[]},{"cell_type":"code","metadata":{"id":"vTw7qXzqWfAR","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1598972972768,"user_tz":-180,"elapsed":1596,"user":{"displayName":"Kirill Romanov","photoUrl":"","userId":"02666825069423801309"}},"outputId":"be86ed33-d7f3-4f3c-b818-a591d9c502fd"},"source":["Counter(test_preds)"],"execution_count":37,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Counter({0: 82241, 1: 33758})"]},"metadata":{"tags":[]},"execution_count":37}]},{"cell_type":"code","metadata":{"id":"XKTtm7F-WiBX","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1598972980406,"user_tz":-180,"elapsed":885,"user":{"displayName":"Kirill Romanov","photoUrl":"","userId":"02666825069423801309"}},"outputId":"ca1ea20f-8b6d-40ec-c9c2-1b5196c49815"},"source":["int_to_label = {0:\"real\", 1:\"fake\"}\n","pred_labels = [int_to_label[i] for i in test_preds]\n","Counter(pred_labels)"],"execution_count":38,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Counter({'fake': 33758, 'real': 82241})"]},"metadata":{"tags":[]},"execution_count":38}]},{"cell_type":"code","metadata":{"id":"Ue24rOq_Wx4t","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"status":"ok","timestamp":1598972990807,"user_tz":-180,"elapsed":950,"user":{"displayName":"Kirill Romanov","photoUrl":"","userId":"02666825069423801309"}},"outputId":"6c2ae233-3bf2-4ca2-f0e2-303264284dd8"},"source":["pred_df = pd.DataFrame( data= {'label':pred_labels})\n","pred_df.head()"],"execution_count":39,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>fake</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>real</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>real</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>real</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>real</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  label\n","0  fake\n","1  real\n","2  real\n","3  real\n","4  real"]},"metadata":{"tags":[]},"execution_count":39}]},{"cell_type":"code","metadata":{"id":"mOXN3qaDzbg5","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598972996467,"user_tz":-180,"elapsed":1054,"user":{"displayName":"Kirill Romanov","photoUrl":"","userId":"02666825069423801309"}}},"source":["pred_df.to_csv('/content/drive/My Drive/fnews/submission_gpt2_ensemble.csv', index=False)"],"execution_count":40,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}]}